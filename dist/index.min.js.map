{
  "version": 3,
  "sources": ["../index.ts", "../utils.ts", "../kana.ts", "../graphSearch.ts"],
  "sourcesContent": ["import type { Furigana, Graph, Sentence, Tree } from \"./interfaces\";\nimport { findOccurrences, insert, reverse, reverseUniq } from \"./utils\";\n\n/**\n * Ensures all synonyms are present and along furigana boundaries\n */\nfunction validateSynonyms(sentence: Sentence): boolean {\n  const rawRubies = sentence.furigana.map((f) =>\n    typeof f === \"string\" ? f : f.ruby\n  );\n  const rawRuby = rawRubies.join(\"\");\n\n  const charToMorphemeIdx = rawRubies.flatMap((str, idx) =>\n    Array.from({ length: str.length }, () => idx)\n  );\n\n  for (const synonym in sentence.synonyms) {\n    const start = rawRuby.indexOf(synonym);\n    if (start < 0) return false;\n    const end = start + synonym.length - 1;\n    // start and end are character indexes\n\n    // the character before this synonym (if it exists) has to be in a different morpheme than\n    // the first character of the synonym\n    if (start > 0 && charToMorphemeIdx[start] === charToMorphemeIdx[start - 1])\n      return false;\n\n    // similarly, the character after this synonym (if it exists) has to be in a different\n    // morpheme than the synonym's last character\n    if (\n      end < rawRuby.length - 1 && // not last character?\n      charToMorphemeIdx[end] === charToMorphemeIdx[end + 1]\n    )\n      return false;\n  }\n  return true;\n}\n\n// records must have the mainline sentence furigana loaded\nfunction parseSynonyms(\n  sentence: Sentence,\n  textToKeys: Record<string, string[]>,\n  keyToPrev: Record<string, string[]>\n) {\n  // boundaries are sub-morpheme, per JMDict-Furigana\n  const rawRubies = sentence.furigana.map((f) =>\n    typeof f === \"string\" ? f : f.ruby\n  );\n  const rawRuby = rawRubies.join(\"\");\n\n  const entryNumber = rawRubies.flatMap((str, idx) =>\n    Array.from({ length: str.length }, () => idx)\n  );\n  for (const [source, dest] of Object.entries(sentence.synonyms ?? {})) {\n    const starts = findOccurrences(rawRuby, source);\n    if (starts.length === 0) {\n      // this should never happen since `validateSynonyms` runs earlier\n      throw new Error(\"synonym not found in raw sentence? \" + source);\n    }\n    for (const start of starts) {\n      const end = start + source.length - 1;\n      // start and end are character indexes\n\n      const startFuriganaIdx = entryNumber[start];\n      const endFuriganaIdx = entryNumber[end];\n      // these are furigana indexes\n\n      let previousKeys: string[] = mainlineKeys(\n        sentence,\n        startFuriganaIdx\n      ).flatMap((key) => keyToPrev[key] ?? []);\n      for (const [fidx, f] of dest.entries()) {\n        previousKeys = insertFurigana({\n          f,\n          fidx: `${source}/${start}/${fidx}`,\n          previousKeys,\n          textToKeys,\n          keyToPrev,\n        });\n      }\n      // outflow: mainline\n      if (sentence.furigana[endFuriganaIdx + 1]) {\n        for (const nextKey of mainlineKeys(sentence, endFuriganaIdx + 1)) {\n          for (const prevKey of previousKeys) {\n            insert(keyToPrev, nextKey, prevKey);\n          }\n        }\n      }\n      // outflow: others\n      const mainlineOutflows = mainlineKeys(sentence, endFuriganaIdx);\n      const allOutflows = Object.entries(keyToPrev)\n        .filter(([, parents]) =>\n          mainlineOutflows.some((targetParent) =>\n            parents.includes(targetParent)\n          )\n        )\n        .map(([key]) => key);\n\n      for (const nextKey of allOutflows) {\n        for (const prevKey of previousKeys) {\n          insert(keyToPrev, nextKey, prevKey, DEDUPE_PLEASE);\n        }\n      }\n    }\n  }\n}\nconst DEDUPE_PLEASE = true;\n\nfunction mainlineKeys(sentence: Sentence, currentIndex: number): string[] {\n  if (currentIndex < 0 || currentIndex >= sentence.furigana.length) {\n    throw new Error(\"weird index\");\n  }\n  const f = sentence.furigana[currentIndex];\n  if (typeof f === \"string\") {\n    return [`${f}/${currentIndex}`];\n  }\n  return [`${f.rt}/${currentIndex}`, `${f.ruby}/${currentIndex}`];\n}\n\ninterface InsertFuriganaArgs {\n  f: Furigana;\n  fidx: number | string;\n  previousKeys: string[];\n  textToKeys: Tree;\n  keyToPrev: Tree;\n}\nfunction insertFurigana({\n  f,\n  fidx,\n  previousKeys,\n  textToKeys,\n  keyToPrev,\n}: InsertFuriganaArgs): string[] {\n  if (typeof f === \"string\") {\n    const newKey = `${f}/${fidx}`;\n    // Step 1. Enroll into text->key map\n    insert(textToKeys, f, newKey);\n    // Step 2. Enroll into key->prev keys map\n    for (const prev of previousKeys) {\n      insert(keyToPrev, newKey, prev);\n    }\n    // Step 3. Last but not least, update prev keys memo\n    return [newKey];\n  }\n  const keysGenerated: string[] = [];\n  {\n    const newRubyKey = `${f.ruby}/${fidx}`;\n    insert(textToKeys, f.ruby, newRubyKey);\n    for (const prev of previousKeys) {\n      insert(keyToPrev, newRubyKey, prev);\n    }\n    keysGenerated.push(newRubyKey);\n  }\n  {\n    const newRtKey = `${f.rt}/${fidx}`;\n    insert(textToKeys, f.rt, newRtKey);\n    for (const prev of previousKeys) {\n      insert(keyToPrev, newRtKey, prev);\n    }\n    keysGenerated.push(newRtKey);\n  }\n  return keysGenerated;\n}\n\nexport function sentenceToGraph(sentence: Sentence): Graph {\n  if (!validateSynonyms(sentence)) {\n    throw new Error(\"wat\");\n  }\n  const textToKeys: Tree = {};\n  const keyToPrev: Tree = {};\n\n  // Go through the straight-line sentence and add furigana as branches\n  let previousKeys: string[] = [];\n  for (const [fidx, f] of sentence.furigana.entries()) {\n    previousKeys = insertFurigana({\n      f,\n      fidx,\n      previousKeys,\n      textToKeys,\n      keyToPrev,\n    });\n  }\n\n  // Now add synonyms\n  parseSynonyms(sentence, textToKeys, keyToPrev);\n\n  // Wrap up\n  const keyToNext = reverse(keyToPrev);\n  const keyToText = reverseUniq(textToKeys);\n  const allKeys = Object.keys(keyToText);\n  const ancestorKeys = new Set(\n    allKeys.filter((key) => !(key in keyToPrev) || keyToPrev[key].length === 0)\n  );\n  const leafKeys = new Set(\n    allKeys.filter((key) => !(key in keyToNext) || keyToNext[key].length === 0)\n  );\n  return {\n    textToKeys,\n    keyToPrev,\n    keyToText,\n    keyToNext,\n    ancestorKeys,\n    leafKeys,\n  };\n}\n\nexport { chunkInput } from \"./graphSearch\";\n", "import type { Tree } from \"./interfaces\";\n\nexport function insert(\n  db: Tree,\n  newKey: string,\n  newVal: string,\n  dedupe = false\n): void {\n  if (!(newKey in db)) {\n    db[newKey] = [];\n  }\n  if (dedupe ? !db[newKey].includes(newVal) : true) {\n    db[newKey].push(newVal);\n  }\n}\n\nexport function reverse(input: Tree): Tree {\n  const ret: Tree = {};\n  for (const k in input) {\n    for (const v of input[k]) {\n      insert(ret, v, k);\n    }\n  }\n  return ret;\n}\nexport function reverseUniq(input: Tree): Record<string, string> {\n  const ret: Record<string, string> = {};\n  for (const k in input) {\n    for (const v of input[k]) {\n      if (v in ret) throw new Error(\"non-unique values\");\n      ret[v] = k;\n    }\n  }\n  return ret;\n}\n\nfunction cumulativeSum(v: number[]): number[] {\n  const ret = v.slice();\n  for (const i of ret.keys()) {\n    ret[i] += ret[i - 1] ?? 0;\n  }\n  return ret;\n}\nexport function findOccurrences(haystack: string, needle: string): number[] {\n  let hits: number[] = [];\n  let position = -1;\n  while ((position = haystack.indexOf(needle, position + 1)) >= 0) {\n    hits.push(position);\n  }\n  return hits;\n}\n/**\n * A bit faster than `findOccurrences(a, b).length`\n */\nfunction findNumOccurrences(haystack: string, needle: string): number {\n  let hits = 0;\n  let position = -1;\n  while ((position = haystack.indexOf(needle, position + 1)) >= 0) {\n    hits++;\n  }\n  return hits;\n}\nexport function max<T>(v: T[], map: (x: T) => number): T {\n  if (v.length === 0) throw new Error(\"empty\");\n  let bestX = v[0];\n  let bestY = map(bestX);\n  //TODO make this iterator so we don't scan the first twice and don't slice (allocate new array)\n  for (const x of v) {\n    const y = map(x);\n    if (y > bestY) {\n      bestY = y;\n      bestX = x;\n    }\n  }\n  return bestX;\n}\n\nexport function longest(v: string[]): string {\n  if (v.length === 0) throw new Error(\"empty\");\n  return v.reduce((prev, curr) => (curr.length > prev.length ? curr : prev));\n}\n\nexport function groupBy<X, Y extends number | string>(\n  xs: X[],\n  f: (x: X) => Y\n): Map<Y, X[]> {\n  const ret = new Map<Y, X[]>();\n  for (const x of xs) {\n    const y = f(x);\n    const hit = ret.get(y);\n    if (!hit) {\n      ret.set(y, [x]);\n    } else {\n      hit.push(x);\n    }\n  }\n  return ret;\n}\n\nexport function countElements<X>(xs: X[]): Map<X, number> {\n  const ret = new Map<X, number>();\n  for (const x of xs) {\n    ret.set(x, (ret.get(x) ?? 0) + 1);\n  }\n  return ret;\n}\n", "const hiragana =\n  \"\u3041\u3042\u3043\u3044\u3045\u3046\u3047\u3048\u3049\u304A\u304B\u304C\u304D\u304E\u304F\u3050\u3051\u3052\u3053\u3054\u3055\u3056\u3057\u3058\u3059\u305A\u305B\u305C\u305D\u305E\u305F\u3060\u3061\u3062\u3063\u3064\u3065\u3066\u3067\u3068\u3069\u306A\u306B\u306C\u306D\u306E\u306F\u3070\u3071\u3072\u3073\u3074\u3075\u3076\u3077\u3078\u3079\u307A\u307B\u307C\u307E\u307F\u3080\u3081\u3082\u3083\u3084\u3085\u3086\u3087\u3088\u3089\u308A\u308B\u308C\u308D\u308E\u308F\u3090\u3091\u3092\u3093\u3094\u3095\u3096\";\nconst katakana =\n  \"\u30A1\u30A2\u30A3\u30A4\u30A5\u30A6\u30A7\u30A8\u30A9\u30AA\u30AB\u30AC\u30AD\u30AE\u30AF\u30B0\u30B1\u30B2\u30B3\u30B4\u30B5\u30B6\u30B7\u30B8\u30B9\u30BA\u30BB\u30BC\u30BD\u30BE\u30BF\u30C0\u30C1\u30C2\u30C3\u30C4\u30C5\u30C6\u30C7\u30C8\u30C9\u30CA\u30CB\u30CC\u30CD\u30CE\u30CF\u30D0\u30D1\u30D2\u30D3\u30D4\u30D5\u30D6\u30D7\u30D8\u30D9\u30DA\u30DB\u30DC\u30DE\u30DF\u30E0\u30E1\u30E2\u30E3\u30E4\u30E5\u30E6\u30E7\u30E8\u30E9\u30EA\u30EB\u30EC\u30ED\u30EE\u30EF\u30F0\u30F1\u30F2\u30F3\u30F4\u30F5\u30F6\";\n\nif (hiragana.length !== katakana.length) {\n  throw new Error(\"Kana strings not same length?\");\n}\n\nconst kata2hiraMap: Map<string, string> = new Map([]);\nconst hira2kataMap: Map<string, string> = new Map([]);\nhiragana.split(\"\").forEach((h, i) => {\n  kata2hiraMap.set(katakana[i], h);\n  hira2kataMap.set(h, katakana[i]);\n});\n\nexport function kata2hira(s: string) {\n  return s\n    .split(\"\")\n    .map((c) => kata2hiraMap.get(c) || c)\n    .join(\"\");\n}\nexport function hira2kata(s: string) {\n  return s\n    .split(\"\")\n    .map((c) => hira2kataMap.get(c) || c)\n    .join(\"\");\n}\n\n/*\nThere are other ways of doing this. In Unicode, katakana is 96 codepoints above hiragana. So\n`String.fromCharCode(hiragana.charCodeAt(0) + 96)` will produce katakana. In speed tests though, the above Map-based\napproach had the least variability in runtime (200 to 800 microseconds), while arithmetic-based approaches used 100 to\n1500 microseconds.\n*/\n", "import { Chunk, type Graph } from \"./interfaces\";\nimport { kata2hira } from \"./kana\";\nimport { longest, max } from \"./utils\";\n\nfunction findMatchingWords(inputHiragana: string, { textToKeys }: Graph) {\n  if (!inputHiragana) return undefined;\n  const matchingWords: string[] = [];\n  for (const word in textToKeys) {\n    if (inputHiragana.startsWith(kata2hira(word))) {\n      matchingWords.push(word);\n    }\n  }\n  return matchingWords;\n}\n\nexport function findGreedyPath(\n  input: string,\n  graph: Graph\n): { result: string; firstKey: string }[] {\n  const inputHiragana = kata2hira(input);\n  const heads = findMatchingWords(inputHiragana, graph) ?? [];\n  const keys = heads.flatMap((word) => graph.textToKeys[word]) ?? [];\n  return keys.map((key) => ({\n    firstKey: key,\n    result: followGreedy(input, key, graph),\n  }));\n}\n\nfunction followGreedy(input: string, startKey: string, graph: Graph): string {\n  // base case (1) end of input\n  if (!input) return input;\n\n  const { keyToNext, keyToText } = graph;\n  const head = keyToText[startKey];\n  const headHiragana = kata2hira(head);\n  const inputHiragana = kata2hira(input);\n\n  // validation\n  if (!inputHiragana.startsWith(headHiragana)) throw new Error(\"bad startKey\");\n\n  const nextKeys =\n    keyToNext[startKey]?.filter((key) =>\n      inputHiragana.startsWith(headHiragana + kata2hira(keyToText[key]))\n    ) ?? [];\n  const headAsInput = input.slice(0, head.length);\n\n  // base case (2) end of graph\n  if (nextKeys.length === 0) return headAsInput;\n\n  const rest = input.slice(head.length);\n  const downstream = nextKeys.map((key) => followGreedy(rest, key, graph));\n  return headAsInput + longest(downstream);\n}\n\nexport function chunkInput(input: string, graph: Graph): Chunk[] {\n  const chunks: Chunk[] = [];\n  let rest = input;\n  while (rest) {\n    const hits = findGreedyPath(rest, graph);\n    if (hits.length === 0) {\n      chunks.push({ text: rest[0], status: \"unknown\", start: false });\n      rest = rest.slice(1);\n    } else {\n      const hit = max(hits, (h) => h.result.length);\n      chunks.push({\n        text: hit.result,\n        status: \"ok\",\n        start: graph.ancestorKeys.has(hit.firstKey),\n      });\n      rest = rest.slice(hit.result.length);\n    }\n  }\n  return chunks;\n}\n"],
  "mappings": "0bAAA,IAAAA,EAAA,GAAAC,EAAAD,EAAA,gBAAAE,EAAA,oBAAAC,ICEO,SAASC,EACdC,EACAC,EACAC,EACAC,EAAS,GACH,CACAF,KAAUD,IACdA,EAAGC,CAAM,EAAI,CAAC,IAEZ,CAAAE,GAAS,CAACH,EAAGC,CAAM,EAAE,SAASC,CAAM,IACtCF,EAAGC,CAAM,EAAE,KAAKC,CAAM,CAE1B,CAEO,SAASE,EAAQC,EAAmB,CACzC,IAAMC,EAAY,CAAC,EACnB,QAAWC,KAAKF,EACd,QAAWG,KAAKH,EAAME,CAAC,EACrBR,EAAOO,EAAKE,EAAGD,CAAC,EAGpB,OAAOD,CACT,CACO,SAASG,EAAYJ,EAAqC,CAC/D,IAAMC,EAA8B,CAAC,EACrC,QAAWC,KAAKF,EACd,QAAWG,KAAKH,EAAME,CAAC,EAAG,CACxB,GAAIC,KAAKF,EAAK,MAAM,IAAI,MAAM,mBAAmB,EACjDA,EAAIE,CAAC,EAAID,CACX,CAEF,OAAOD,CACT,CASO,SAASI,EAAgBC,EAAkBC,EAA0B,CAC1E,IAAIC,EAAiB,CAAC,EAClBC,EAAW,GACf,MAAQA,EAAWH,EAAS,QAAQC,EAAQE,EAAW,CAAC,IAAM,GAC5DD,EAAK,KAAKC,CAAQ,EAEpB,OAAOD,CACT,CAYO,SAASE,EAAOC,EAAQC,EAA0B,CACvD,GAAID,EAAE,SAAW,EAAG,MAAM,IAAI,MAAM,OAAO,EAC3C,IAAIE,EAAQF,EAAE,CAAC,EACXG,EAAQF,EAAIC,CAAK,EAErB,QAAWE,KAAKJ,EAAG,CACjB,IAAMK,EAAIJ,EAAIG,CAAC,EACXC,EAAIF,IACNA,EAAQE,EACRH,EAAQE,EAEZ,CACA,OAAOF,CACT,CAEO,SAASI,EAAQN,EAAqB,CAC3C,GAAIA,EAAE,SAAW,EAAG,MAAM,IAAI,MAAM,OAAO,EAC3C,OAAOA,EAAE,OAAO,CAACO,EAAMC,IAAUA,EAAK,OAASD,EAAK,OAASC,EAAOD,CAAK,CAC3E,CChFA,IAAME,EACJ,igBACIC,EACJ,igBAEF,GAAID,EAAS,SAAWC,EAAS,OAC/B,MAAM,IAAI,MAAM,+BAA+B,EAGjD,IAAMC,EAAoC,IAAI,IAAI,CAAC,CAAC,EAC9CC,EAAoC,IAAI,IAAI,CAAC,CAAC,EACpDH,EAAS,MAAM,EAAE,EAAE,QAAQ,CAACI,EAAGC,IAAM,CACnCH,EAAa,IAAID,EAASI,CAAC,EAAGD,CAAC,EAC/BD,EAAa,IAAIC,EAAGH,EAASI,CAAC,CAAC,CACjC,CAAC,EAEM,SAASC,EAAUC,EAAW,CACnC,OAAOA,EACJ,MAAM,EAAE,EACR,IAAKC,GAAMN,EAAa,IAAIM,CAAC,GAAKA,CAAC,EACnC,KAAK,EAAE,CACZ,CCjBA,SAASC,EAAkBC,EAAuB,CAAE,WAAAC,CAAW,EAAU,CACvE,GAAI,CAACD,EAAe,OACpB,IAAME,EAA0B,CAAC,EACjC,QAAWC,KAAQF,EACbD,EAAc,WAAWI,EAAUD,CAAI,CAAC,GAC1CD,EAAc,KAAKC,CAAI,EAG3B,OAAOD,CACT,CAEO,SAASG,EACdC,EACAC,EACwC,CACxC,IAAMP,EAAgBI,EAAUE,CAAK,EAGrC,QAFcP,EAAkBC,EAAeO,CAAK,GAAK,CAAC,GACvC,QAASJ,GAASI,EAAM,WAAWJ,CAAI,CAAC,GAAK,CAAC,GACrD,IAAKK,IAAS,CACxB,SAAUA,EACV,OAAQC,EAAaH,EAAOE,EAAKD,CAAK,CACxC,EAAE,CACJ,CAEA,SAASE,EAAaH,EAAeI,EAAkBH,EAAsB,CAE3E,GAAI,CAACD,EAAO,OAAOA,EAEnB,GAAM,CAAE,UAAAK,EAAW,UAAAC,CAAU,EAAIL,EAC3BM,EAAOD,EAAUF,CAAQ,EACzBI,EAAeV,EAAUS,CAAI,EAC7Bb,EAAgBI,EAAUE,CAAK,EAGrC,GAAI,CAACN,EAAc,WAAWc,CAAY,EAAG,MAAM,IAAI,MAAM,cAAc,EAE3E,IAAMC,EACJJ,EAAUD,CAAQ,GAAG,OAAQF,GAC3BR,EAAc,WAAWc,EAAeV,EAAUQ,EAAUJ,CAAG,CAAC,CAAC,CACnE,GAAK,CAAC,EACFQ,EAAcV,EAAM,MAAM,EAAGO,EAAK,MAAM,EAG9C,GAAIE,EAAS,SAAW,EAAG,OAAOC,EAElC,IAAMC,EAAOX,EAAM,MAAMO,EAAK,MAAM,EAC9BK,EAAaH,EAAS,IAAKP,GAAQC,EAAaQ,EAAMT,EAAKD,CAAK,CAAC,EACvE,OAAOS,EAAcG,EAAQD,CAAU,CACzC,CAEO,SAASE,EAAWd,EAAeC,EAAuB,CAC/D,IAAMc,EAAkB,CAAC,EACrBJ,EAAOX,EACX,KAAOW,GAAM,CACX,IAAMK,EAAOjB,EAAeY,EAAMV,CAAK,EACvC,GAAIe,EAAK,SAAW,EAClBD,EAAO,KAAK,CAAE,KAAMJ,EAAK,CAAC,EAAG,OAAQ,UAAW,MAAO,EAAM,CAAC,EAC9DA,EAAOA,EAAK,MAAM,CAAC,MACd,CACL,IAAMM,EAAMC,EAAIF,EAAOG,GAAMA,EAAE,OAAO,MAAM,EAC5CJ,EAAO,KAAK,CACV,KAAME,EAAI,OACV,OAAQ,KACR,MAAOhB,EAAM,aAAa,IAAIgB,EAAI,QAAQ,CAC5C,CAAC,EACDN,EAAOA,EAAK,MAAMM,EAAI,OAAO,MAAM,CACrC,CACF,CACA,OAAOF,CACT,CHnEA,SAASK,EAAiBC,EAA6B,CACrD,IAAMC,EAAYD,EAAS,SAAS,IAAKE,GACvC,OAAOA,GAAM,SAAWA,EAAIA,EAAE,IAChC,EACMC,EAAUF,EAAU,KAAK,EAAE,EAE3BG,EAAoBH,EAAU,QAAQ,CAACI,EAAKC,IAChD,MAAM,KAAK,CAAE,OAAQD,EAAI,MAAO,EAAG,IAAMC,CAAG,CAC9C,EAEA,QAAWC,KAAWP,EAAS,SAAU,CACvC,IAAMQ,EAAQL,EAAQ,QAAQI,CAAO,EACrC,GAAIC,EAAQ,EAAG,MAAO,GACtB,IAAMC,EAAMD,EAAQD,EAAQ,OAAS,EAUrC,GALIC,EAAQ,GAAKJ,EAAkBI,CAAK,IAAMJ,EAAkBI,EAAQ,CAAC,GAMvEC,EAAMN,EAAQ,OAAS,GACvBC,EAAkBK,CAAG,IAAML,EAAkBK,EAAM,CAAC,EAEpD,MAAO,EACX,CACA,MAAO,EACT,CAGA,SAASC,EACPV,EACAW,EACAC,EACA,CAEA,IAAMX,EAAYD,EAAS,SAAS,IAAKE,GACvC,OAAOA,GAAM,SAAWA,EAAIA,EAAE,IAChC,EACMC,EAAUF,EAAU,KAAK,EAAE,EAE3BY,EAAcZ,EAAU,QAAQ,CAACI,EAAKC,IAC1C,MAAM,KAAK,CAAE,OAAQD,EAAI,MAAO,EAAG,IAAMC,CAAG,CAC9C,EACA,OAAW,CAACQ,EAAQC,CAAI,IAAK,OAAO,QAAQf,EAAS,UAAY,CAAC,CAAC,EAAG,CACpE,IAAMgB,EAASC,EAAgBd,EAASW,CAAM,EAC9C,GAAIE,EAAO,SAAW,EAEpB,MAAM,IAAI,MAAM,sCAAwCF,CAAM,EAEhE,QAAWN,KAASQ,EAAQ,CAC1B,IAAMP,EAAMD,EAAQM,EAAO,OAAS,EAG9BI,EAAmBL,EAAYL,CAAK,EACpCW,EAAiBN,EAAYJ,CAAG,EAGlCW,EAAyBC,EAC3BrB,EACAkB,CACF,EAAE,QAASI,GAAQV,EAAUU,CAAG,GAAK,CAAC,CAAC,EACvC,OAAW,CAACC,EAAMrB,CAAC,IAAKa,EAAK,QAAQ,EACnCK,EAAeI,EAAe,CAC5B,EAAAtB,EACA,KAAM,GAAGY,CAAM,IAAIN,CAAK,IAAIe,CAAI,GAChC,aAAAH,EACA,WAAAT,EACA,UAAAC,CACF,CAAC,EAGH,GAAIZ,EAAS,SAASmB,EAAiB,CAAC,EACtC,QAAWM,KAAWJ,EAAarB,EAAUmB,EAAiB,CAAC,EAC7D,QAAWO,KAAWN,EACpBO,EAAOf,EAAWa,EAASC,CAAO,EAKxC,IAAME,EAAmBP,EAAarB,EAAUmB,CAAc,EACxDU,EAAc,OAAO,QAAQjB,CAAS,EACzC,OAAO,CAAC,CAAC,CAAEkB,CAAO,IACjBF,EAAiB,KAAMG,GACrBD,EAAQ,SAASC,CAAY,CAC/B,CACF,EACC,IAAI,CAAC,CAACT,CAAG,IAAMA,CAAG,EAErB,QAAWG,KAAWI,EACpB,QAAWH,KAAWN,EACpBO,EAAOf,EAAWa,EAASC,EAASM,CAAa,CAGvD,CACF,CACF,CACA,IAAMA,EAAgB,GAEtB,SAASX,EAAarB,EAAoBiC,EAAgC,CACxE,GAAIA,EAAe,GAAKA,GAAgBjC,EAAS,SAAS,OACxD,MAAM,IAAI,MAAM,aAAa,EAE/B,IAAME,EAAIF,EAAS,SAASiC,CAAY,EACxC,OAAI,OAAO/B,GAAM,SACR,CAAC,GAAGA,CAAC,IAAI+B,CAAY,EAAE,EAEzB,CAAC,GAAG/B,EAAE,EAAE,IAAI+B,CAAY,GAAI,GAAG/B,EAAE,IAAI,IAAI+B,CAAY,EAAE,CAChE,CASA,SAAST,EAAe,CACtB,EAAAtB,EACA,KAAAqB,EACA,aAAAH,EACA,WAAAT,EACA,UAAAC,CACF,EAAiC,CAC/B,GAAI,OAAOV,GAAM,SAAU,CACzB,IAAMgC,EAAS,GAAGhC,CAAC,IAAIqB,CAAI,GAE3BI,EAAOhB,EAAYT,EAAGgC,CAAM,EAE5B,QAAWC,KAAQf,EACjBO,EAAOf,EAAWsB,EAAQC,CAAI,EAGhC,MAAO,CAACD,CAAM,CAChB,CACA,IAAME,EAA0B,CAAC,EACjC,CACE,IAAMC,EAAa,GAAGnC,EAAE,IAAI,IAAIqB,CAAI,GACpCI,EAAOhB,EAAYT,EAAE,KAAMmC,CAAU,EACrC,QAAWF,KAAQf,EACjBO,EAAOf,EAAWyB,EAAYF,CAAI,EAEpCC,EAAc,KAAKC,CAAU,CAC/B,CACA,CACE,IAAMC,EAAW,GAAGpC,EAAE,EAAE,IAAIqB,CAAI,GAChCI,EAAOhB,EAAYT,EAAE,GAAIoC,CAAQ,EACjC,QAAWH,KAAQf,EACjBO,EAAOf,EAAW0B,EAAUH,CAAI,EAElCC,EAAc,KAAKE,CAAQ,CAC7B,CACA,OAAOF,CACT,CAEO,SAASG,EAAgBvC,EAA2B,CACzD,GAAI,CAACD,EAAiBC,CAAQ,EAC5B,MAAM,IAAI,MAAM,KAAK,EAEvB,IAAMW,EAAmB,CAAC,EACpBC,EAAkB,CAAC,EAGrBQ,EAAyB,CAAC,EAC9B,OAAW,CAACG,EAAMrB,CAAC,IAAKF,EAAS,SAAS,QAAQ,EAChDoB,EAAeI,EAAe,CAC5B,EAAAtB,EACA,KAAAqB,EACA,aAAAH,EACA,WAAAT,EACA,UAAAC,CACF,CAAC,EAIHF,EAAcV,EAAUW,EAAYC,CAAS,EAG7C,IAAM4B,EAAYC,EAAQ7B,CAAS,EAC7B8B,EAAYC,EAAYhC,CAAU,EAClCiC,EAAU,OAAO,KAAKF,CAAS,EAC/BG,EAAe,IAAI,IACvBD,EAAQ,OAAQtB,GAAQ,EAAEA,KAAOV,IAAcA,EAAUU,CAAG,EAAE,SAAW,CAAC,CAC5E,EACMwB,EAAW,IAAI,IACnBF,EAAQ,OAAQtB,GAAQ,EAAEA,KAAOkB,IAAcA,EAAUlB,CAAG,EAAE,SAAW,CAAC,CAC5E,EACA,MAAO,CACL,WAAAX,EACA,UAAAC,EACA,UAAA8B,EACA,UAAAF,EACA,aAAAK,EACA,SAAAC,CACF,CACF",
  "names": ["tabito_lib_exports", "__export", "chunkInput", "sentenceToGraph", "insert", "db", "newKey", "newVal", "dedupe", "reverse", "input", "ret", "k", "v", "reverseUniq", "findOccurrences", "haystack", "needle", "hits", "position", "max", "v", "map", "bestX", "bestY", "x", "y", "longest", "prev", "curr", "hiragana", "katakana", "kata2hiraMap", "hira2kataMap", "h", "i", "kata2hira", "s", "c", "findMatchingWords", "inputHiragana", "textToKeys", "matchingWords", "word", "kata2hira", "findGreedyPath", "input", "graph", "key", "followGreedy", "startKey", "keyToNext", "keyToText", "head", "headHiragana", "nextKeys", "headAsInput", "rest", "downstream", "longest", "chunkInput", "chunks", "hits", "hit", "max", "h", "validateSynonyms", "sentence", "rawRubies", "f", "rawRuby", "charToMorphemeIdx", "str", "idx", "synonym", "start", "end", "parseSynonyms", "textToKeys", "keyToPrev", "entryNumber", "source", "dest", "starts", "findOccurrences", "startFuriganaIdx", "endFuriganaIdx", "previousKeys", "mainlineKeys", "key", "fidx", "insertFurigana", "nextKey", "prevKey", "insert", "mainlineOutflows", "allOutflows", "parents", "targetParent", "DEDUPE_PLEASE", "currentIndex", "newKey", "prev", "keysGenerated", "newRubyKey", "newRtKey", "sentenceToGraph", "keyToNext", "reverse", "keyToText", "reverseUniq", "allKeys", "ancestorKeys", "leafKeys"]
}
